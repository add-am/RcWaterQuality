---
title: "Pesticides Data Analysis"
subtitle: "A Healthy Waters Partnership Analysis"
description: "This script analyses the pesticide sampling locations in the Dry Tropics region. The output of this is used in the Dry Tropics Technical Report."
author: "Adam Shand"
format: html
params:
  script_fyear: 2024 
---

```{r}

#load in a custom function to get yaml parameters
source("functions/get_quarto_params.R")

params <- get_quarto_params()

#return each param as its own object
script_fyear <- params$script_fyear

```

# Introduction

The purpose of this script is to analyse the pesticides data from the sampling site locations for the freshwater pesticides index and calculate standardised scores for the Dry Tropics Technical Report. This data is used in the body of the technical report as well as the appendix.

This script uses data in the pesticides masterdata spreadsheet. The data in this spreadsheet is manually transcribed from the spreadsheet that is created by DETSI's online PRM tool. The spreadsheet created by this tool is saved in the main DTPHW filing system (not GitHub) and just the numbers are copied over.

# Script Set Up

This script requires multiple core spatial packages, each of which is loaded below. Key variables and paths are also created.

```{r}
#| label: load packages

#use pacman function to load and install (if required) all other packages
pacman::p_load(tidyverse, glue, here, janitor, readxl)

#install/load the custom RcTools package
#pak::pak("add-am/RcTools")
library(RcTools)

#load in the custom function used to create the read and write folders for the script
source("functions/setup_helper.R")

#get the required paths
paths <- setup_helper(script_fyear)
data_path <- paths[[1]]
output_path <- paths[[2]]

#turn off scientific notation
options(scipen = 999)

#manually change data path for now
data_path <- "data/pesticides/raw/"

```

# Load Data

Now the script is set up we need to load in all of the required datasets. For this script, we will only need the metadata and master data spreadsheets.

```{r}
#| label: load in all data

#read in the target sheet and drop unwanted column names, then run the custom naming cleaning function
site_metadata <- read_excel(glue("{data_path}/pesticides_metadata.xlsx"),
                            sheet = "Current_Sites", na = c("", "NA", "NULL", "null")) |> 
  select(-c(SiteName, AKA)) |> 
  name_cleaning()


#read in the target sheet and drop unwanted column names, then run the custom naming cleaning function
site_data <- read_excel(glue("{data_path}/pesticides_data_master.xlsx"), 
                         sheet = "CLMP", na = c("", "NA", "NULL", "null")) |> 
  select(-SiteName) |> 
  name_cleaning()
  
#join metadata and results together
pesticides_all <- site_metadata |> 
  left_join(site_data)

```

# Edit Data

We first need to perform some very simple edits of the data.

```{r}
#| label: edit the data

pesticides_all <- pesticides_all |> 
  mutate(across(where(is.numeric), \(x) round(x, 2)))
  
```

# Analyse Data

Given the simplicity of the dataset we can now move straight to calculating the final pesticides score. This is achieved using a custom scoring function that we create below.

```{r}
#| label: analyse data

#calculate scores
pesticides_all <- value_to_score(
  pesticides_all,
  MsPaf,
  "Pesticides"
)

#then grades
pesticides_all <- score_to_grade(pesticides_all, MsPafScore)

```

# Save Data

And now we can save the results, we will use a custom function to colour the cells appropriately.

```{r}
#| label: save results

#save the entire dataset
write_csv(pesticides_all, glue("{output_path}/pesticides_full_results.csv"))

#cut down dataset to only the proportions
pesticides_report_ready <- pesticides_all |> 
  filter(str_detect(Date, as.character(script_fyear))) |> 
  select(BasinOrZone, Date, ProportionInsecticides, ProportionOtherHerbicides, 
  ProportionPsiiHerbicides, SpeciesProtected, MsPafScore, MsPafGrade, Risk)

save_n3_table(
  pesticides_report_ready,
  glue("{output_path}/pesticides_scores"),
  7,
  1:nrow(pesticides_report_ready),
  "Report Card"
)

```

# Unique Pesticides Detected

An additional section we include in the technical report is a summary of any pesticides in particular that were detected. Essentially we can just check for entries in the concentration data that do not have "<" in the operator column. i.e. the concentration value was not less that the Limit of Reporting.

```{r}
#| label: unique pesticides detected

#load in the raw concentration data
raw_concentration <- read_csv(glue("{data_path}/pesticide_concentrations.csv"))

#create a datetime object out of our financial year variable
fy_datetime_obj_min <- dmy_hm(glue("01-07-{script_fyear-1} 00:00"))
fy_datetime_obj_max <- dmy_hm(glue("30-06-{script_fyear} 00:00"))

#filter for just our year of interest
raw_concentration <- raw_concentration |> 
  mutate(Date = dmy_hm(`Date Time`)) |> 
  filter(Date >= fy_datetime_obj_min & Date <= fy_datetime_obj_max)

#filter for rows that are not below LOR
above_lor <- raw_concentration |> 
  filter(is.na(Operator))

#extract unique pesticides for each of our locations
unique_pesticides <- above_lor |> 
  select(`Site Name`, Analyte) |> 
  unique()

#save the dataset
write_csv(unique_pesticides, glue("{output_path}/unique_pesticides.csv"))

```

```{r}


```














