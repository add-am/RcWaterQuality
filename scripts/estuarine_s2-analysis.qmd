---
title: "Estuarine Water Quality Exploratory Data Analysis"
subtitle: "A Healthy Waters Partnership Analysis"
description: "Script 2 in a series of script designed to analyse, score, and present estuarine water quality in the Dry Tropics region. The ouTput of this is used in the Dry Tropics Technical Report."
author: "Adam Shand"
format: html
params:
  script_crs: "EPSG:7844"
  script_fyear: 2024
  sites_removed: FALSE
---

::: {.callout-note}
## Note
Params with the yaml of this script allow a choice between datasets that have "offending" sites removed, and datasets that contain all data. Choose appropriately depending on your needs!
:::

# Introduction

The purpose of this script is to perform the main data analysis, as well as calculate final results for estuarine water quality data in the Dry Tropics technical report. Key steps include:

 - Loading in data prepared by script 1 of the series.
 - Re-calculating summary stats to be saved to the main output folder (note these were originally calculated in script 1 to help with EDA checks).
 - Calculating the monthly median values for all indicators
 - Calculating the annual median values (from the monthly median values) for all indicators
 - Calculating the standardised scores for all indicators for all:
    + Watercourses
 - Summing indicators to calculate indicator categories
 - Summing indicator categories to calculate the water quality index
 - Calculating the standardised scores for all indicator, indicator categories, and indices, by taking the mean value for each:
    + Sub Basin
    + Basin
 - Weighting all calculated scores for each sub basin based on their proportion of the basin they are within
 - Summing the weighted sub basins scores to calculated weighted basin scores
 - Converting all scores (weighted and unweighted) to grades.
 - Rounding final values (floor rounding where appropriate).
 - Saving various data tables that will be used in the technical report.
 
# Script Set Up

This script requires multiple core spatial packages, each of which is loaded below. Key variables and paths are also created.

```{r}
#| label: load packages

#use pacman function to load and install (if required) all other packages
pacman::p_load(tidyverse, glue, here, janitor, openxlsx2, reactable)

#install/load the custom RcTools package
#pak::pak("add-am/RcTools")
library(RcTools)

params <- get_quarto_params()

#return each param as its own object
script_crs <- params$script_crs
script_fyear <- params$script_fyear
sites_removed <- params$sites_removed

#load in the custom function used to create the read and write folders for the script
source("functions/setup_helper.R")

#get the required paths
paths <- setup_helper(script_fyear)
data_path <- paths[[1]]
output_path <- paths[[2]]

#turn off scientific notation
options(scipen = 999)

```

# Load Data

Data for this script is provided in a single spreadsheet that was prepared by script 1 in this series of scripts. Please note that script 1 may have removed some offending values, if this is the case a warning will notify as such.

```{r}
#| label: load data
#| warning: true

if (file.exists(glue("{data_path}_sites_removed.csv")) & sites_removed == TRUE){ #if post removed exists, and that is what you want

  #read in data
  estuarine_wq_all <- read_csv(glue("{data_path}_sites_removed.csv"))
  
  #provide a notifying warning
  warning("The data that has been loaded in has had some values removed as per the QA/QC checks 
          performed in script 1 of this series. Please confirm this is the dataset you would like
          to use.")
  
} else if (file.exists(glue("{data_path}.csv"))){ #if a dataset that never needed removal exists
  
  #read in data
  estuarine_wq_all <- read_csv(glue("{data_path}.csv"))
  
} else { #otherwise, take the pre removal dataset
  
  #read in data
  estuarine_wq_all <- read_csv(glue("{data_path}_pre_removal.csv"))
    
}

#run the custom naming cleaning function
estuarine_wq_all <- name_cleaning(estuarine_wq_all)

#convert columns to factors and give them the custom order we use in the technical report
estuarine_wq_all <- estuarine_wq_all |> 
  mutate(across(c(BasinOrZone, SubBasinOrSubZone, WatercourseOrGeographicArea), factor),
         BasinOrZone = fct_relevel(BasinOrZone, "Ross", "Black"), 
         SubBasinOrSubZone = fct_relevel(SubBasinOrSubZone, "Bohle River", "Lower Ross River", "Stuart Creek", 
                                 "Alligator Creek", "Bluewater Creek", "Rollingstone Creek", "Crystal Creek"), 
         WatercourseOrGeographicArea = fct_relevel(WatercourseOrGeographicArea, "Bohle River", "Louisa Creek", "Ross Creek", "Ross River", 
                                   "Sandfly Creek", "Alligator Creek", "Althaus Creek", "Bluewater Creek",
                                   "Sleeper Log Creek", "Camp Oven Creek", "Saltwater Creek",  "Rollingstone Creek", 
                                   "Crystal Creek")) 

```

# Calculate Results

Once all the data has been loaded in we can begin to calculate results. However the first step is to calculate some side statistics such as number of samples, and number of months sampled.

```{r}
#| label: calculate side statistics

#select current fy and add the month column
estuarine_wq_cy <- estuarine_wq_all |> filter(Fy == script_fyear) |> 
  mutate(Month = month(Date, label = TRUE))

#calculate the number of months sampled, and the total number of samples
estuarine_wq_cy <- estuarine_wq_cy |> 
  group_by(Region, Environment, BasinOrZone, SubBasinOrSubZone, WatercourseOrGeographicArea, Fy, Indicator) |> 
  mutate(NMonths = length(unique(Month)),
         NSamples = n()) |> 
  ungroup()

```

## Monthly Medians

Below we calculate monthly median values for each watercourse, this is particularly important for the CLMP samples that have multiple samples per month, less so for the others.

```{r}
#| label: calculate monthly medians

#calculate monthly medians for each indicator
est_wq_monthly <- estuarine_wq_cy |> 
  group_by(
    Region, Environment, BasinOrZone, SubBasinOrSubZone, WatercourseOrGeographicArea, 
    Fy, Month, NMonths, NSamples, Indicator, Units, Wqo, Sf, SubBasinArea, SubBasinProportionOfBasin) |> 
  summarise(MonthlyMedianValues = median(Values, na.rm = TRUE)) |> 
  ungroup()

```

## Annual Medians

Then we will calculate annual medians, plus twentieth and eightieth percentiles which are used in the standardised scoring function.

```{r}
#| label: Calculate annual medians

#group up using the same reverse grouping trick and calculate values
est_wq_annual <- est_wq_monthly |> 
  group_by(across(c(-MonthlyMedianValues, -Month))) |> 
  mutate(AnnualMedianValues = median(MonthlyMedianValues, na.rm = TRUE),
         Twentieth = quantile(MonthlyMedianValues, probs = 0.2, na.rm = TRUE),
         Eightieth = quantile(MonthlyMedianValues, probs = 0.8, na.rm = TRUE)) |> 
  ungroup()

```

### Side Tangent: Summary Stats

Part of the technical report includes summary statistics. Below we stylize and present these stats. The table is showed below.

```{r}
#| label: Summary statistics

#stylize table
estuarine_summary_stats <- est_wq_annual |> 
  select(WatercourseOrGeographicArea, Indicator, NSamples, NMonths, AnnualMedianValues, Wqo, Sf) |> 
  unique() |> 
  mutate(across(c(Indicator), factor),
         Indicator = fct_relevel(Indicator, "DIN", "TP", "FRP", "Turbidity", "High_DO", "Low_DO"),
         AnnualMedianValues = round(AnnualMedianValues, 3)) |> 
  arrange(Indicator, WatercourseOrGeographicArea)

#save the data
save_n3_table(
  estuarine_summary_stats,
  glue("{output_path}/summary_statistics"),
  target_columns = c(5:6),
  target_rows = 1:nrow(estuarine_summary_stats),
  scheme = "Summary Statistic"
)

#Important note: Variables for which "success" is to be greater than the water quality objective need to have their colours reversed.

#create object to present in the rendered quarto document
summary_table_present <- reactable(estuarine_summary_stats)

```

`r summary_table_present`

## Standardised Scores: Watercourses

Once annual medians are done we can calculate the standardised scores for each watercourse using a custom function.

```{r}
#| label: calculate standardised scores

#use the custom function from RcTools to convert values to standardised scores
est_wq_annual_scored <- value_to_score(
  df = est_wq_annual,
  value = AnnualMedianValues,
  value_type = "Water Quality",
  water_type = "Estuarine",
  indicator = Indicator,
  wqo = Wqo,
  sf = Sf,
  eightieth = Eightieth,
  twentieth = Twentieth
)

#refine dataset to just columns and rows we want
est_wq_annual_scored <- est_wq_annual_scored |> 
  select(
    Region, BasinOrZone, SubBasinOrSubZone, WatercourseOrGeographicArea, 
    Indicator, AnnualMedianValuesScore, SubBasinArea, SubBasinProportionOfBasin) |> 
  distinct() |> 
  filter(!is.na(AnnualMedianValuesScore))

```

## Indicator Categories and Indices

To calculate indicator category and index scores we first need to prepared the data somewhat.

```{r}
#| label: prepare data

#pivot data wider and convert columns to factors to set up for the impending calculation
est_wq_annual_wide <- est_wq_annual_scored |> 
  pivot_wider(names_from = Indicator, values_from = AnnualMedianValuesScore)

#clean the names up
est_wq_annual_wide <- name_cleaning(est_wq_annual_wide)

```

Before we can then perform the require rowwise operations.

```{r}
#| label: calculate indicator category and index scores

#calculate indicator categories and indices scores
est_wq_all <- est_wq_annual_wide |> 
  rowwise() |> 
  mutate(Nutrients = mean(c(Din, Tp), na.rm = TRUE),
         MinDo = min(c(HighDo, LowDo), na.rm = TRUE),
         PhysChem = mean(c(Turbidity, MinDo), na.rm = TRUE),
         OverallWq = mean(c(Nutrients, PhysChem), na.rm = TRUE),
         across(where(is.numeric), ~ifelse(is.infinite(.), NA, .))) |>
  ungroup()

```

## Standarised Scores: Sub_Basins, Basins

Once all scores have been calculated at the watercourse level, they can be averaged up to each of the subsequent levels (sub basin and then basin).

```{r}
#| label: calculate scores for sub basins and basins

#group at each level and get the mean of each indicator, indicator category, and index, at that level
sub_basin_scores <- est_wq_all |> 
  group_by(Region, BasinOrZone, SubBasinOrSubZone, SubBasinArea, SubBasinProportionOfBasin) |> 
  summarise(across(
    c(Din, HighDo, LowDo, Turbidity, Tp, Nutrients, PhysChem, OverallWq), 
    \(x) mean(x, na.rm = TRUE)
  ))

#as above
basin_scores <- est_wq_all |> 
  group_by(Region, BasinOrZone) |> 
  summarise(across(
    c(Din, HighDo, LowDo, Turbidity, Tp, Nutrients, PhysChem, OverallWq), 
    \(x) mean(x, na.rm = TRUE)
  ))

#combine each of the datasets
est_wq_all_scores <- bind_rows(est_wq_all, sub_basin_scores, basin_scores) 

```

### Side Tangent: Save Sub Basin Scores

A second side tangent we will take here is to save the sub basin scores for nutrients, phys-chem, and the water quality index. These scores need to be added to the appendix.

```{r}
#| label: save sub basin scores

#select specific rows
sub_basin_scores_save <- sub_basin_scores |> ungroup() |> 
  select(SubBasinOrSubZone, Nutrients, PhysChem, OverallWq) |> 
  mutate(across(where(is.numeric), floor))

save_n3_table(
  sub_basin_scores_save,
  glue("{output_path}/est_appendix_sub_basin_scores"),
  c(2:4),
  1:nrow(sub_basin_scores_save),
  scheme = "Report Card"
)

```

## Weighted Scores

Now every single score has been calculated, all of them can be weighted appropriately.

```{r}
#| label: create weight scores

#if the score has an associated sub basin weighting, calculate as such
est_wq_sub_basin_weighted <- est_wq_all_scores |> 
  mutate(across(
    c("Din", "Frp", "HighDo", "LowDo", "Tp", "Turbidity", "Nutrients", "PhysChem", "OverallWq"), 
    ~ .*SubBasinProportionOfBasin, 
    .names = "{.col}Weighted"))

#select all rows that don't have a watercourse, (i.e. only sub basins), then group by basin and sum to get a weighted basin score.
est_wq_basin_weighted <- est_wq_sub_basin_weighted |> 
  filter(is.na(WatercourseOrGeographicArea)) |> 
  group_by(BasinOrZone) |> 
  mutate(across(
    c(
      "SubBasinArea","DinWeighted", "FrpWeighted", "HighDoWeighted", "LowDoWeighted", 
      "TpWeighted", "TurbidityWeighted", "NutrientsWeighted", "PhysChemWeighted", "OverallWqWeighted"
    ), 
    ~ if_else(is.na(SubBasinOrSubZone), sum(., na.rm = TRUE), .)
  )) |> 
  ungroup()

#combined each dataset together, remove duplicated rows, and remove the unweighted basin rows
est_wq_all_weighted <- rbind(est_wq_sub_basin_weighted, est_wq_basin_weighted) |> 
  unique() |> 
  filter(!is.na(BasinOrZone) & !is.na(OverallWqWeighted))

```

## Scores to Grades

Finally, both the weighted and unweighted scores can be converted to a grade.

```{r}
#| label: convert score to grade

est_wq_all_scores_grades_raw <- score_to_grade(est_wq_all_weighted, 7:length(est_wq_all_weighted))

```

## Floor Rounding

A quirk of the water quality calculations is that all final scores are presented as whole numbers, and any values with decimals are rounded down (floor rounding).

```{r}
#| label: floor round results

#floor all numeric columns except those that contain the word "Prop" or as these are proportions (need decimals)
est_wq_all_scores_grades_floor <- est_wq_all_scores_grades_raw |> 
  mutate(across(where(is.numeric) & !contains(c("Prop", "Weight")), \(x) floor(x)),
         across(where(is.numeric) & contains("Weight"), \(x) round(x, 1)),
         across(contains("Prop"), \(x) round(x, 2)))

```

# Saving Results

A series of tables need to be created to save the results in a digestible format. These tables include:

 - The entire raw data set
 - The entire dataset with rounding applied (floor rounding where appropriate).
 - Nutrients table (main report; Din, Tp, Nutrients (unweighted), Area (% and km2), Nutrients (sub basin weighted), Nutrients (basin weighted))
 - Phys Chem table (main report; High DO, Low DO, Turbidity, Phys Chem (unweighted), Area (% and km2), Phys Chem (sub basin weighted), Phys Chem (basin weighted))
 - A summary table (which has already been saved further up).

```{r}
#| label: save data as tables

#save entire raw dataset
write_csv(est_wq_all_scores_grades_raw, glue("{output_path}/est_wq_all_scores_grades_raw.csv"))

#save entire rounded dataset
write_csv(est_wq_all_scores_grades_floor, glue("{output_path}/est_wq_all_scores_grades_floor.csv"))

#do some yuck rearranging of data to make results align with the desired output tables.
nutri_physchem_prep <- est_wq_all_scores_grades_floor |> 
  rename("Weighting(%)" = SubBasinProportionOfBasin, "Area(km2)" = SubBasinArea) |> 
  mutate(
    SubBasinNutrientsWeighted = case_when(
      !is.na(WatercourseOrGeographicArea) ~ NA,
      is.na(SubBasinOrSubZone) ~ NA,
      TRUE ~ NutrientsWeighted),
    SubBasinPhysChemWeighted = case_when(
      !is.na(WatercourseOrGeographicArea) ~ NA, 
      is.na(SubBasinOrSubZone) ~ NA,
      TRUE ~ PhysChemWeighted),
    NutrientsWeighted = case_when(
      !is.na(SubBasinOrSubZone) ~ NA, 
      TRUE ~ NutrientsWeighted),
    PhysChemWeighted = case_when(
      !is.na(SubBasinOrSubZone) ~ NA, 
      TRUE ~ PhysChemWeighted),
    "Area(km2)" = case_when(
      !is.na(WatercourseOrGeographicArea) ~ NA, 
      TRUE ~ `Area(km2)`),
    "Weighting(%)" = case_when(
      is.na(`Weighting(%)`) ~ 1, 
      !is.na(WatercourseOrGeographicArea) ~ NA, 
      TRUE ~ `Weighting(%)`))

#select columns for the nutrients table
nutrients_table <- nutri_physchem_prep |> 
  select(
    BasinOrZone, SubBasinOrSubZone, WatercourseOrGeographicArea, Din, Tp, Nutrients, 
    "Weighting(%)", "Area(km2)", SubBasinNutrientsWeighted, NutrientsWeighted) |> 
  arrange(BasinOrZone, SubBasinOrSubZone, WatercourseOrGeographicArea)

#select columns for the PhysChem table
physchem_table <- nutri_physchem_prep |> 
  select(
    BasinOrZone, SubBasinOrSubZone, WatercourseOrGeographicArea, HighDo, LowDo, Turbidity, 
    PhysChem, "Weighting(%)", "Area(km2)", SubBasinPhysChemWeighted, PhysChemWeighted) |> 
  arrange(BasinOrZone, SubBasinOrSubZone, WatercourseOrGeographicArea)

save_n3_table(
  nutrients_table,
  glue("{output_path}/est_nutrients"),
  c(4:10),
  1:nrow(nutrients_table),
  scheme = "Report Card"
)

save_n3_table(
  physchem_table,
  glue("{output_path}/est_physchem"),
  c(4:11),
  1:nrow(physchem_table),
  scheme = "Report Card"
)

```

```{r}


```
