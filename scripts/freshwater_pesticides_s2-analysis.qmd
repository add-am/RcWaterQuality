---
title: "Pesticides Data Analysis"
subtitle: "A Healthy Waters Partnership Analysis"
description: "This script analyses the pesticide sampling locations in the Dry Tropics region. The output of this is used in the Dry Tropics Technical Report."
author: "Adam Shand"
format: html
params:
  project_crs: "EPSG:7844"
  target_fyear: 2024 
---

# Introduction

The purpose of this script is to analyse the pesticides data from the sampling site locations for the freshwater pesticides index and calculate standardised scores for the Dry Tropics Technical Report. This data is used in the body of the technical report as well as the appendix.

This script uses data in the pesticides masterdata spreadsheet. The data in this spreadsheet is manually transcribed from the spreadsheet that is created by DETSI's online PRM tool. The spreadsheet created by this tool is saved in the main DTPHW filing system (not GitHub) and just the numbers are copied over.

# Script Set Up

This script requires multiple core spatial packages, each of which is loaded below. Key variables and paths are also created.

```{r}
#| label: load packages

#use pacman function to load and install (if required) all other packages
pacman::p_load(tidyverse, glue, here, janitor, readxl)

#load in the custom function used to create the read and write folders for the script
source(here("functions/script_setup.R"))

#run the function to create the folders and paths
script_setup()

##read in the custom function to clean column names into our specific style
source(here("functions/name_cleaning.R"))

#set project variables
proj_crs <- params$project_crs

```

# Load Data

Now the script is set up we need to load in all of the required datasets. For this script, we will only need the metadata and master data spreadsheets.

```{r}
#| label: load in all data

#read in the target sheet and drop unwanted column names, then run the custom naming cleaning function
site_metadata <- read_excel(glue("{data_path}/dt_wq_freshwater_pesticides_metadata.xlsx"),
                            sheet = "Current_Sites", na = c("", "NA", "NULL", "null")) |> 
  select(-c(SiteName, AKA)) |> 
  name_cleaning()


#read in the target sheet and drop unwanted column names, then run the custom naming cleaning function
site_data <- read_excel(glue("{data_path}/dt_wq_freshwater_pesticides_data_master.xlsx"), 
                         sheet = "CLMP", na = c("", "NA", "NULL", "null")) |> 
  select(-SiteName) |> 
  name_cleaning()
  
#join metadata and results together
pesticides_all <- site_metadata |> 
  left_join(site_data)

```

# Edit Data

We first need to perform some very simple edits of the data.

```{r}
#| label: edit the data

pesticides_all <- pesticides_all |> 
  mutate(across(where(is.numeric), \(x) round(x, 2)))
  
```

# Analyse Data

Given the simplicity of the dataset we can now move straight to calculating the final pesticides score. This is achieved using a custom scoring function that we create below.

```{r}
#| label: analyse data

#create a standardizing function
standardise_scores <- function(col){
  col = case_when(col <= 1 ~ 81 + abs((19 - ((col - 0) * (19/1)))),
                  col > 1 & col < 5 ~ 61 + abs((19.9 - ((col - 1.01) * (19.9/3.99)))),
                  col >= 5 & col < 10 ~ 41 + abs((19.9 - ((col - 5) * (19.9/4.99)))),
                  col >= 10 & col < 20 ~ 21 + abs((19.9 - ((col - 10) * (19.9/9.99)))),
                  TRUE ~ 0 + abs((20.9 - ((col - 20) * (20.9/79.99)))))
}

#run the function
pesticides_all <- pesticides_all |> 
  mutate(Score = floor(standardise_scores(MsPaf)))

#assign a grade
pesticides_all <- pesticides_all |> 
  mutate(Grade = case_when(Score >= 81 ~ "A",
                           Score >= 61 ~ "B",
                           Score >= 41 ~ "C",
                           Score >= 21 ~ "D",
                           T ~ "E"))

```

# Save Data

And now we can save the results, we will use a custom function to colour the cells appropriately.

```{r}
#| label: save results

#save the entire dataset
write_csv(pesticides_all, glue("{output_path}/pesticides_full_results.csv"))

#cut down dataset to only the proportions
pesticides_report_ready <- pesticides_all |> 
  filter(str_detect(Date, as.character(current_fyear))) |> 
  select(BasinOrZone, Date, ProportionInsecticides, ProportionOtherHerbicides, ProportionPsiiHerbicides, SpeciesProtected, Score, Grade, Risk)

#load in custom function
source(here("functions/cond_form_rc_grades.R"))

#save data
cond_form_rc_grades(pesticides_report_ready, glue("{output_path}/pesticide_scores"), cols = 7, method = "Numeric")

```

# Unique Pesticides Detected

An additional section we include in the technical report is a summary of any pesticides in particular that were detected. Essentially we can just check for entries in the concentration data that do not have "<" in the operator column. i.e. the concentration value was not less that the Limit of Reporting.

```{r}
#| label: unique pesticides detected

#load in the raw concentration data
raw_concentration <- read_csv(glue("{data_path}/pesticide_concentrations.csv"))

#create a datetime object out of our financial year variable
fy_datetime_obj_min <- dmy_hm(glue("01-07-{current_fyear-1} 00:00"))
fy_datetime_obj_max <- dmy_hm(glue("30-06-{current_fyear} 00:00"))

#filter for just our year of interest
raw_concentration <- raw_concentration |> 
  mutate(Date = dmy_hm(`Date Time`)) |> 
  filter(Date >= fy_datetime_obj_min & Date <= fy_datetime_obj_max)

#filter for rows that are not below LOR
above_lor <- raw_concentration |> 
  filter(is.na(Operator))

#extract unique pesticides for each of our locations
unique_pesticides <- above_lor |> 
  select(`Site Name`, Analyte) |> 
  unique()

#save the dataset
write_csv(unique_pesticides, glue("{output_path}/unique_pesticides.csv"))

```














